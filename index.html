<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content=""/>
  <meta property="og:description" content=""/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>GenAssist: Making Image Generation Accessible</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="module"
  src="https://gradio.s3-us-west-2.amazonaws.com/3.35.2/gradio.js">
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title">GenAssist: Making Image Generation Accessible</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                  <a href="http://www.minahuh.com" target="_blank">Mina Huh</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.yihaopeng.tw/" target="_blank">Yi-Hao Peng</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="http://www.amypavel.com" target="_blank">Amy Pavel</a><sup>1</sup>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">UT Austin<sup>1</sup>, CMU<sup>2</sup>, <br>ACM UIST 2023 - Best Paper Award üèÜ</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://dl.acm.org/doi/abs/10.1145/3586183.3606735" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    <span class="link-block">
                      <a href="https://minahuh.com/assets/pdf/GenAssist-Alt-Text.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Accessible PDF</span>
                    </a>
                  </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->
                 <!-- Demo link -->
                 <!-- <span class="link-block">
                  <a 
                  class="external-link button is-normal is-rounded ">
                  <span class="icon">
                    <i class="fa fa-image"></i>
                  </span>
                  <span>Demo coming soon...</span>
                </a>
              </span> -->

                  

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/minarainbow/GenAssist" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->


                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2302.14117" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" style="margin-bottom: 2%;" alt="Teaser image that illustrates how GenAssist generates the comparison description and per image descriptions in the summary table. First, GenAssist takes the input of text prompt ``A young chef is cooking dinner for his parents'' and the four images generated using the prompt. Then, based on the prompt, GenAssist uses GPT4 to ask prompt verification questions and use BLIP2 to answer them. GenAssist also asks questions based on the individual image captions using GPT4 and BLIP2. In addition to prompt verification questions and image based questions, GenAssist also asks questions related to visual content and styles and answer them using BLIP2, Detic and CLIP. Finally, using all of the visual information, the comparison description (similarities and differences) and the per image descriptions are generated using GPT4."/>
      <h2 class="subtitle has-text-centered">
        <b>GenAssist</b> is a system that enables blind or low vision creators to generate images by providing rich visual descriptions
        of the generation results. With the given text prompt and a set of generated images, GenAssist uses a large language model (GPT4) to generate prompt verification questions based on the text prompt, and image-based questions based on individual image
        captions (BLIP-2). GenAssist also extracts the visual content and style of the images using the vision-language model (CLIP, BLIP2), and object detection model (Detic). All of the information is then summarized using the GPT-4 to generate the <b>comparison
        descriptions </b> and <b> per-image descriptions </b>.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Prompt Verification</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
      <img src="static/images/prompt-verification1.jpg" width="70%" alt="A figure that illustrates an example of prompt verification questions. On the left is the input with the instruction ``Generate visual questions that verify whether each part of the prompt is correct. Number the questions.'' and the input prompt ``A young chef is cooking dinner for his parents.'' On the right is the output prompt verification questions: 1. Is there a chef in the image? 2. How old is the young chef? 3. Is the young chef cooking the food? 4. Are the parents present in the image?"/>
      <h2 class="subtitle">
        To help users assess how well their generated
        images adhered to their prompt, GenAssist provides prompt verification. 
        To perform prompt verification, we first use GPT-4
        to generate visual questions that verify each part of the prompt.
      </h2><br><br>
      <img src="static/images/prompt-verification2.jpg" width="70%" alt="A figure that illustrates an example of prompt verification questions and their answers for each of the four images. First question is ``Is there a chef in the image?'' and the answer is all yes for four images. Second question is ``How old is the young chef?'' and the first three images answer ``Young kid'' while the last image says ``Young man''. The third question is ``Is the young chef cooking food?'' and the answers are all yes for the four images. The final question is ``Are the parents present in the image?'' and the answer is all yes except for the second image."/>
      <h2 class="subtitle">
        We use BLIP-2 to generate answers to the prompt verification questions for each of
        the four generated images.
      </h2><br><br>
      <img src="static/images/prompt-verification3.jpg" width="70%" alt="This figure illustrates the example of the summary descriptions for the prompt verification questions. For the question ``Is there a chef in the image?'', the summary description is ``Three images depict a young kid, while Image 4 depicts a young man.'' The second question ``Are the parents present in the image?'', the answer summary is ``Three images show parents present in the image, while image 2 does not.''"/>
      <h2 class="subtitle">
        To help users quickly find which images do or do not adhere to the prompt, we use GPT-4 to summarize the responses to each question.
      </h2>
      </div>
      </div>
    </div>
  </div>

<br><hr style="background-color: lightgray;"><br>

  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Visual Content & Style Extraction</h2><br>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/content-style1.jpg" width="70%" alt="This image illustrates an example of content and style questions answered by BLIP-2. The answers are provided for the same tutorial images. For the question ``What is the setting of the image?'', the answers are all kitchen. For the question ``What are the subjects of the image?'', the answers are father and children for the first image, chef, kitchen and vegetables for the second image, father, mother and son for the third and fourth image. For the question ``What is the emotion of the image?'', all answers are happy. For the question about the usage ``Where would this image be used?'', the answers are ``on a website'', ``in a cookbook'', ``a children's cooking class'', and ``on a website''. Finally, for the question ``What are the main colors?'', the first image answers ``Brown, blue, yellow'', the second image answers ``Black, white, red, green'', the third image answers ``blue and white'', and the final image answers ``Red, yellow, green''."/><br>
          <h2 class="subtitle has-text-centered">
            To enable access to image content and style details that were not specified in the prompt, we extract the visual content and visual style of the generated image candidates. 
            We answer 5 questions (setting, subjects, emotion, likely use, colors) using Visual Question Answering with BLIP-2:
          </h2><br><br>
          <img src="static/images/content-style2.jpg" width="70%" alt="This figure shows an example of the object detection results using Detic per image. The first image depicts spoon, pot, cup, tub, apron, bowl, etc. The second image depicts spoon, sink, tomato, lettuce, hat, bowl, etc. The third image shows spoon, fork, knife, apple, sausage, plate, etc. The fourth image shows spoon, pot, window, flowerpot, plate, frog, etc."/><br>
          <h2 class="subtitle has-text-centered">
            To extract objects information, we use Detic with an open detection vocabulary to enable users to access all objects:
          </h2><br><br>
          <img src="static/images/content-style3.jpg" width="70%" alt="This figures shows the answers related to content and style of the images that were retrieved using CLIP model. First for the medium of the image, image 1 answers cartoon, storybook, and illustration, image 2 answers a stock photo, image 3 answers vector art, and image 4 answers cartoon, storybook, and illustration. For the lighting of the image, all four images answer natural lighting. For the perspective of the images, image 1, 3 and 4 answer medium shot while the second image answers centered shot. For the errors in the image, only image 1 answers poorly drawn hands but not other three images."/><br>
          <h2 class="subtitle has-text-centered">
            To extract information of medium, lighting, perspective, and errors, we answer the following questions for each image candidate by using CLIP to determine the similarity between the image and a limited set of answer choices:
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-centered">
      <h2 class="title is-3">Description Summarization</h2>
      <div id="results-carousel" class="carousel results-carousel is-centered ">
       <div class="item" >
        <!-- Your image here -->
        <div class="row" style="margin-bottom: 3%;">
          <div class="col-4">
            <img src="static/images/example1.png" width="80%" style="margin-left: 15%;"alt="A grid of four images generated using the prompt ``a young chef is cooking dinner for his parents.'' The first image is an illustration of a dad cooking with his two children. The second image is a photo of a young boy cooking alone in the kitchen. The third image is a vector art image that depicts parents and their son cooking. The fourth image is an illustration of parents and their son who is a young man cooking in the kitchen with a wide window." />
          </div>
          <div class="col-8">
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Prompt</b>
            </h2>
            <h2 class="subtitle is-5" style="font-style: italic;">
              "A young chef is cooking the dinner for his parents"
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Similarities</b>
            </h2>
            <h2 class="subtitle is-5">
              The four images are all related to cooking/food preparation. They all have a natural lighting source, and the emotions depicted in all of them are happy. 
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Differences</b>
            </h2>
            <h2 class="subtitle is-5">
              The differences among these images include medium (vector art, stock photo), focus on subject (a boy, a father, a mother), availability of ingredients, kitchen size, utensils being used, whether family members are wearing aprons, whether the family members are cooking individually or collectively, etc.
            </h2>
          </div>
        </div>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="row" style="margin-bottom: 3%;">
          <div class="col-4">
            <img src="static/images/example1-1.png" width="80%" style="margin-left: 15%;" alt="An illustration of a dad cooking with his two children." />
          </div>
          <div class="col-7 align-self-center">
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Prompt</b>
            </h2>
            <h2 class="subtitle is-5" style="font-style: italic;">
              "A young chef is cooking the dinner for his parents"
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Per Image Description - Image 1</b>
            </h2>
            <h2 class="subtitle is-5">
              A colorful cartoon illustration of a father and his two young children cooking in a bright kitchen with natural lighting. The kitchen countertop is brown and there is a happy expression on the father's face as there is a smell of food in the air. This illustration is likely to be used on a website.
            </h2>
          </div>
        </div>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="row" style="margin-bottom: 3%;">
          <div class="col-4">
            <img src="static/images/example1-2.png" width="80%" style="margin-left: 15%;" alt="A photo of a young boy cooking alone in the kitchen."/>
          </div>
          <div class="col-7 align-self-center">
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Prompt</b>
            </h2>
            <h2 class="subtitle is-5" style="font-style: italic;">
              "A young chef is cooking the dinner for his parents"
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Per Image Description - Image 2</b>
            </h2>
            <h2 class="subtitle is-5">
              In this stock photo, a young boy wears a chef's hat as he stands in a modern kitchen. He is preparing a salad using a knife while ingredients are on the kitchen counter. The boy looks happy. The colors used are black, white, red and green. This image would likely be used in a cookbook to show children preparing healthy meals.
            </h2>
          </div>
        </div>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="row" style="margin-bottom: 3%;">
          <div class="col-4">
            <img src="static/images/example1-3.png" width="80%" style="margin-left: 15%;" alt="A vector art image that depicts parents and their son cooking."/>
          </div>
          <div class="col-7 align-self-center">
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Prompt</b>
            </h2>
            <h2 class="subtitle is-5" style="font-style: italic;">
              "A young chef is cooking the dinner for his parents"
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Per Image Description - Image 3</b>
            </h2>
            <h2 class="subtitle is-5">
              In this vector art image, a family is cooking together in a well-lit kitchen. There is a young boy chef with a man and woman, preparing food with pots, pans and spoons on a gas stove. They're happy while cooking snacks for their family. The main colors used are blue and white. This image would fit in a children's cooking class.
            </h2>
          </div>
        </div>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="row" style="margin-bottom: 3%;">
          <div class="col-4">
            <img src="static/images/example1-4.png" width="80%" style="margin-left: 15%;" alt="The fourth image is an illustration of parents and their son who is a young man cooking in the kitchen with a wide window."/>
          </div>
          <div class="col-7 align-self-center">
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Prompt</b>
            </h2>
            <h2 class="subtitle is-5" style="font-style: italic;">
              "A young chef is cooking the dinner for his parents"
            </h2>
            <h2 class="subtitle is-5" style="margin-bottom: 0%;">
              <b>Per Image Description - Image 4</b>
            </h2>
            <h2 class="subtitle is-5">
              A cartoon of a family preparing food in a brightly lit small kitchen with natural lighting. The subjects are a young man chef, a father, a mother standing near a counter with pots, pans, and utensils. There is a large window in the kitchen. 
            </h2>
          </div>
        </div>
      </div>
  </div><br><br>
  <h2 class="subtitle has-text-centered">
    To enable users to quickly assess their image results, we summarize our pipeline results (prompt verification, prompt guideline, and caption-detail
    question-answer pairs for each image) to create a <b>image similarities and differences</b> and a <b>per image description</b> for
    each image using GPT-4.
  </h2>
</div>
</div>
</section>
<!-- End image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Examples</h2>
      <div class="columns is-centered has-text-centered">
        <iframe
        src="https://mina1004h-genassist-demo.hf.space"
        frameborder="0"
        width="1200"
        height="1200"
      ></iframe>
      </div>
    </div>
  </div>
</section>






<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Evaluation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/evaluation.jpg" width="70%" style="margin-right: 20%;"/>
          <h2 class="subtitle has-text-centered">
            After the video editing tasks, we measured the cognitive load using NASA-TLX. AVscript significantly outperformed users‚Äô own video editing tools in mental demand, temporal demand, effort, and frustration.
            AVscript was also rated significantly better in the confidence in the output, independence in reviewing output, and
            helpfulness in identifying errors.
        </h2>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Presentation Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/1pDjm-n_Jkk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Supplementary Video</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/yqH8P8Ml0FQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{huh2023genassist,
        title={GenAssist: Making Image Generation Accessible},
        author={Huh, Mina and Peng, Yi-Hao and Pavel, Amy},
        booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
        pages={1--17},
        year={2023}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
